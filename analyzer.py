#!/usr/bin/env python3
"""
STOCK SENTIMENT ANALYZER (GitHub-Deployable Version)
Fixed version for GitHub Actions deployment
"""

import os
import requests
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Must be before pyplot import
import matplotlib.pyplot as plt
import yfinance as yf
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import json
from datetime import datetime
import logging
import time

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Configuration
CONFIG = {
    "top_50_stocks": [
        "AAPL", "MSFT", "AMZN", "GOOGL", "META", "TSLA", "NVDA", "JPM", "JNJ", "V",
        "PG", "HD", "MA", "DIS", "PYPL", "ADBE", "NFLX", "CRM", "BAC", "KO",
        "PEP", "INTC", "CMCSA", "XOM", "WMT", "ABT", "TMO", "AVGO", "CSCO", "PFE",
        "MRK", "ABBV", "ACN", "DHR", "VZ", "T", "UNH", "LIN", "ORCL", "NKE",
        "PM", "LLY", "AMD", "MDT", "BMY", "HON", "QCOM", "INTU", "AMGN", "COP"
    ],
    "elon_stocks": ["TSLA"],
    "api_keys": {
        "alpha_vantage": os.getenv('ALPHAVANTAGE_KEY', 'demo'),
        "newsapi": os.getenv('NEWSAPI_KEY', '')
    }
}

# Initialize NLP model with fallback
sentiment_pipeline = None
try:
    from transformers import pipeline
    sentiment_pipeline = pipeline(
        "sentiment-analysis",
        model="distilbert-base-uncased-finetuned-sst-2-english",
        device=-1  # Use CPU
    )
    logging.info("‚úÖ Transformers model loaded successfully")
except Exception as e:
    logging.warning(f"‚ö†Ô∏è Could not load transformers model: {e}")
    sentiment_pipeline = None

def get_sentiment_fallback(text):
    """Simple keyword-based sentiment analysis"""
    positive = ["rise", "gain", "up", "bullish", "beat", "buy", "strong", "surge", "rally"]
    negative = ["fall", "drop", "down", "bearish", "miss", "sell", "weak", "plunge", "crash"]
    
    text_lower = text.lower()
    pos_score = sum(1 for word in positive if word in text_lower)
    neg_score = sum(1 for word in negative if word in text_lower)
    
    if pos_score > neg_score:
        return "POSITIVE"
    elif neg_score > pos_score:
        return "NEGATIVE"
    else:
        return "NEUTRAL"

def get_stock_data(ticker):
    """Fetch stock data with enhanced error handling"""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="1d", prepost=True)
        
        if hist.empty:
            logging.warning(f"‚ö†Ô∏è No data for {ticker}: Empty history")
            return None
            
        open_price = hist['Open'].iloc[0]
        close_price = hist['Close'].iloc[-1]
        
        # Try to get after-hours price
        try:
            info = stock.fast_info
            post_market_price = info.get('postMarketPrice', close_price)
        except:
            post_market_price = close_price
        
        regular_change = ((close_price - open_price) / open_price) * 100
        post_change = ((post_market_price - close_price) / close_price) * 100
        
        return {
            "symbol": ticker,
            "regular_change": round(float(regular_change), 2),
            "post_change": round(float(post_change), 2),
            "current_price": round(float(post_market_price), 2),
            "open_price": round(float(open_price), 2),
            "close_price": round(float(close_price), 2)
        }
        
    except Exception as e:
        logging.error(f"üö® Failed to get data for {ticker}: {str(e)}")
        return None

def fetch_all_stocks():
    """Fetch stock data for all configured tickers"""
    all_tickers = list(set(CONFIG["top_50_stocks"] + CONFIG["elon_stocks"]))
    logging.info(f"üìä Fetching data for {len(all_tickers)} stocks...")
    
    valid_stocks = {}
    
    # Use ThreadPoolExecutor for concurrent requests
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(get_stock_data, all_tickers))
    
    for result in results:
        if result:
            valid_stocks[result["symbol"]] = result
    
    logging.info(f"‚úÖ Successfully fetched data for {len(valid_stocks)} stocks")
    return valid_stocks

def fetch_news():
    """Fetch news from multiple sources with fallbacks"""
    news_items = []
    
    # Try Alpha Vantage first
    if CONFIG['api_keys']['alpha_vantage'] not in ['', 'demo']:
        try:
            url = f"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=TSLA,AAPL,MSFT&apikey={CONFIG['api_keys']['alpha_vantage']}"
            response = requests.get(url, timeout=10)
            data = response.json()
            
            for item in data.get("feed", [])[:10]:
                tickers = [t["ticker"] for t in item.get("ticker_sentiment", [])]
                news_items.append({
                    "title": item.get("title", ""),
                    "source": item.get("source", "AlphaVantage"),
                    "tickers": tickers
                })
            logging.info(f"üì∞ Fetched {len(news_items)} news items from Alpha Vantage")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Alpha Vantage API failed: {e}")
    
    # Try NewsAPI if we don't have enough news
    if len(news_items) < 5 and CONFIG['api_keys']['newsapi']:
        try:
            url = f"https://newsapi.org/v2/everything?q=stocks&sortBy=publishedAt&apiKey={CONFIG['api_keys']['newsapi']}"
            response = requests.get(url, timeout=10)
            data = response.json()
            
            for article in data.get("articles", [])[:5]:
                news_items.append({
                    "title": article.get("title", ""),
                    "source": article.get("source", {}).get("name", "NewsAPI"),
                    "tickers": []  # NewsAPI doesn't provide ticker mapping
                })
            logging.info(f"üì∞ Added {len(news_items)} total news items with NewsAPI")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è NewsAPI failed: {e}")
    
    # Fallback news for testing
    if not news_items:
        news_items = [
            {
                "title": "Tech stocks rally as AI investments surge",
                "source": "Fallback",
                "tickers": ["AAPL", "MSFT", "NVDA"]
            },
            {
                "title": "Tesla reports strong quarterly delivery numbers",
                "source": "Fallback", 
                "tickers": ["TSLA"]
            },
            {
                "title": "Market volatility continues amid economic uncertainty",
                "source": "Fallback",
                "tickers": ["SPY", "QQQ"]
            }
        ]
        logging.info("üì∞ Using fallback news items")
    
    return news_items[:15]  # Limit to 15 items

def analyze_sentiment(text):
    """Analyze sentiment using available method"""
    try:
        if sentiment_pipeline:
            result = sentiment_pipeline(text[:512])[0]
            return result['label']
        else:
            return get_sentiment_fallback(text)
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Sentiment analysis failed: {e}")
        return "NEUTRAL"

def analyze_news(stock_data, news_items):
    """Combine stock data with news sentiment"""
    results = []
    
    for item in news_items:
        try:
            sentiment = analyze_sentiment(item["title"])
            
            # If tickers are provided, use them
            tickers_to_process = item.get("tickers", [])
            
            # If no tickers, try to match with major stocks
            if not tickers_to_process:
                for ticker in ["AAPL", "MSFT", "TSLA", "GOOGL", "META"]:
                    if ticker in stock_data:
                        tickers_to_process.append(ticker)
                        break
            
            for ticker in set(tickers_to_process):
                if ticker in stock_data:
                    try:
                        # Get company name
                        company_name = ticker  # Default fallback
                        try:
                            company_name = yf.Ticker(ticker).info.get('shortName', ticker)
                        except:
                            pass
                        
                        results.append({
                            "Ticker": ticker,
                            "Company": company_name,
                            "Headline": item["title"][:200],  # Truncate long headlines
                            "Sentiment": sentiment,
                            "Regular Change": stock_data[ticker]["regular_change"],
                            "After Hours": stock_data[ticker]["post_change"],
                            "Current Price": stock_data[ticker]["current_price"],
                            "Source": item["source"],
                            "Timestamp": datetime.now().isoformat()
                        })
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è Error processing {ticker}: {e}")
                        continue
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Error processing news item: {e}")
            continue
    
    return pd.DataFrame(results) if results else None

def save_outputs(df):
    """Save results in multiple formats"""
    if df is None or df.empty:
        logging.error("‚ùå No data to save")
        return False
    
    try:
        # Save JSON
        df.to_json("results.json", orient="records", indent=2)
        logging.info("‚úÖ Saved results.json")
        
        # Save HTML
        with open("results.html", "w") as f:
            f.write(f"""
            <html>
            <head><title>Stock Sentiment Analysis Results</title></head>
            <body>
            <h1>Stock Sentiment Analysis - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</h1>
            {df.to_html(index=False)}
            </body>
            </html>
            """)
        logging.info("‚úÖ Saved results.html")
        
        # Save summary
        with open("summary.txt", "w") as f:
            f.write(f"Stock Sentiment Analysis Summary\n")
            f.write(f"Generated: {datetime.now()}\n")
            f.write(f"Stocks analyzed: {len(df['Ticker'].unique())}\n")
            f.write(f"Total headlines: {len(df)}\n")
            f.write(f"Positive sentiment: {sum(df['Sentiment'] == 'POSITIVE')}\n")
            f.write(f"Negative sentiment: {sum(df['Sentiment'] == 'NEGATIVE')}\n")
            f.write(f"Neutral sentiment: {sum(df['Sentiment'] == 'NEUTRAL')}\n")
        logging.info("‚úÖ Saved summary.txt")
        
        return True
        
    except Exception as e:
        logging.error(f"‚ùå Failed to save outputs: {e}")
        return False

def run_analysis():
    """Main analysis function with comprehensive error handling"""
    try:
        logging.info("üöÄ Starting Stock Sentiment Analysis...")
        
        # Fetch stock data
        logging.info("üìä Fetching stock data...")
        stock_data = fetch_all_stocks()
        if not stock_data:
            logging.error("‚ùå No stock data available - cannot continue")
            return None
        
        logging.info(f"‚úÖ Got data for {len(stock_data)} stocks")
        
        # Fetch news
        logging.info("üì∞ Fetching news...")
        news_items = fetch_news()
        if not news_items:
            logging.error("‚ùå No news data available - cannot continue")
            return None
        
        logging.info(f"‚úÖ Got {len(news_items)} news items")
        
        # Analyze
        logging.info("üîç Analyzing sentiment...")
        try:
            results_df = analyze_news(stock_data, news_items)
        except Exception as e:
            logging.error(f"‚ùå Analysis failed: {e}")
            # Create a minimal dataset as fallback
            results_df = pd.DataFrame([{
                "Ticker": list(stock_data.keys())[0],
                "Company": list(stock_data.keys())[0],
                "Headline": "Analysis completed with limited data",
                "Sentiment": "NEUTRAL",
                "Regular Change": list(stock_data.values())[0]["regular_change"],
                "After Hours": list(stock_data.values())[0]["post_change"],
                "Current Price": list(stock_data.values())[0]["current_price"],
                "Source": "System",
                "Timestamp": datetime.now().isoformat()
            }])
        
        # Save results
        if save_outputs(results_df):
            logging.info("‚úÖ Analysis completed successfully")
            if results_df is not None and not results_df.empty:
                print(f"\nüìä Analysis Results Summary:")
                print(f"Stocks analyzed: {len(results_df['Ticker'].unique())}")
                print(f"Headlines processed: {len(results_df)}")
                
                # Safe top movers display
                try:
                    print(f"\nTop movers:")
                    top_movers = results_df.nlargest(5, 'Regular Change')[['Ticker', 'Regular Change', 'Sentiment']]
                    print(top_movers)
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Could not display top movers: {e}")
                    
            return results_df
        else:
            logging.error("‚ùå Failed to save analysis results")
            return None
            
    except Exception as e:
        logging.error(f"‚ùå Critical analysis failure: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return None

if __name__ == "__main__":
    results = run_analysis()
    if results is not None:
        print("‚úÖ Script completed successfully")
    else:
        print("‚ùå Script failed")
        exit(1)
